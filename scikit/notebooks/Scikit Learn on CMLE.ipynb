{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Income with the Census Income Dataset Using Scikit Learn on ML Engine\n",
    "To use Scikit Learn on ML Engine for predictions, you will need to have a pre-trained model that you can upload to ML Engine. This datalab use the [Census Income Data Set](https://archive.ics.uci.edu/ml/datasets/Census+Income) to create a simple model, train the model, upload the model to ML Engine, and lastly use the model to make predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0: Setup\n",
    "* [Create a project on GCP](https://cloud.google.com/resource-manager/docs/creating-managing-projects)\n",
    "* [Create a Google Cloud Storage Bucket](https://cloud.google.com/storage/docs/quickstart-console)\n",
    "* [Enable Cloud Machine Learning Engine and Compute Engine APIs](https://console.cloud.google.com/flows/enableapi?apiid=ml.googleapis.com,compute_component&_ga=2.217405014.1312742076.1516128282-1417583630.1516128282)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the data\n",
    "The [Census Income Data Set](https://archive.ics.uci.edu/ml/datasets/Census+Income) that this sample\n",
    "uses for training is hosted by the [UC Irvine Machine Learning\n",
    "Repository](https://archive.ics.uci.edu/ml/datasets/). We have hosted the data\n",
    "on Google Cloud Storage in a slightly cleaned form:\n",
    "\n",
    " * Training file is `adult.data.csv`\n",
    " * Evaluation file is `adult.test.csv`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disclaimer\n",
    "The source of this dataset is from a third party. Google provides no representation,\n",
    "warranty, or other guarantees about the validity or any other aspects of this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a directory to hold the data\n",
    "! mkdir census_data\n",
    "\n",
    "# Download the data\n",
    "! curl https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data --output census_data/adult.data\n",
    "! curl https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test --output census_data/adult.test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Train the model \n",
    "First the data is loaded into a numpy array that can be used by Scikit Learn. Then a simple model is created and fit against the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.externals import joblib\n",
    "import tensorflow as tf  # Tensorflow is only used to retrieve data from the census data files\n",
    "\n",
    "\n",
    "# Define the format of your input data including unused columns (These are the columns from the census data files)\n",
    "COLUMNS = (\n",
    "    'age',\n",
    "    'workclass',\n",
    "    'fnlwgt',\n",
    "    'education',\n",
    "    'education-num',\n",
    "    'marital-status',\n",
    "    'occupation',\n",
    "    'relationship',\n",
    "    'race',\n",
    "    'sex',\n",
    "    'capital-gain',\n",
    "    'capital-loss',\n",
    "    'hours-per-week',\n",
    "    'native-country',\n",
    "    'income-level'\n",
    ")\n",
    "\n",
    "# Categorical columns are columns that need to be turned into a numerical value to be used by Scikit Learn\n",
    "CATEGORICAL_COLUMNS = (\n",
    "    'workclass',\n",
    "    'education',\n",
    "    'marital-status',\n",
    "    'occupation',\n",
    "    'relationship',\n",
    "    'race',\n",
    "    'sex',\n",
    "    'native-country'\n",
    ")\n",
    "\n",
    "\n",
    "# Load the training census dataset\n",
    "with tf.gfile.Open('./census_data/adult.data', 'r') as train_data:\n",
    "    raw_training_data = pd.read_csv(train_data, header=None, names=COLUMNS)\n",
    "# Remove the column we are trying to predict ('income-level') from our features list\n",
    "train_features = raw_training_data.drop('income-level', axis=1)\n",
    "# Create our training labels list\n",
    "train_labels = (raw_training_data['income-level'] == ' >50K')\n",
    "\n",
    "\n",
    "# Load the test census dataset\n",
    "with tf.gfile.Open('./census_data/adult.test', 'r') as test_data:\n",
    "    raw_testing_data = pd.read_csv(test_data, names=COLUMNS, skiprows=1)\n",
    "# Remove the column we are trying to predict ('income-level') from our features list\n",
    "test_features = raw_testing_data.drop('income-level', axis=1)\n",
    "# Create our training labels list\n",
    "test_labels = (raw_testing_data['income-level'] == ' >50K.')\n",
    "\n",
    "\n",
    "# Convert the categorical columns to a numerical value in both the training and testing dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoders = {col:LabelEncoder() for col in CATEGORICAL_COLUMNS}\n",
    "\n",
    "for col in CATEGORICAL_COLUMNS:\n",
    "    train_features[col] = encoders[col].fit_transform(train_features[col])\n",
    "\n",
    "for col in CATEGORICAL_COLUMNS:\n",
    "    test_features[col] = encoders[col].fit_transform(test_features[col])\n",
    "\n",
    "\n",
    "# Create and train a classifier\n",
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(train_features, train_labels)\n",
    "\n",
    "# Export the classifier to a file\n",
    "joblib.dump(classifier, 'model.joblib')\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Upload the model\n",
    "Next, you'll need to upload the model to your project's storage bucket in GCS.\n",
    "\n",
    "**Replace** `BUCKET_ID` with the bucket id you used in the setup step.\n",
    "\n",
    "Note: The exact file name of of the exported model you upload to GCS is important! Your model must be named  “model.joblib”, “model.pkl”, or “model.bst” with respect to the library you used to export it. This restriction ensures that the model will be safely reconstructed later by using the same technique for import as was used during export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! gsutil cp ./model.joblib gs://[BUCKET_ID]/model.joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Create a Model resource\n",
    "** Replace ** `MODEL_NAME` with the name for your model. (We used \"scikit_learn_prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! gcloud ml-engine models create [MODEL_NAME] --regions us-central1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Create a Version resource\n",
    "\n",
    "** Replace: **\n",
    "* `VERSION` - with your version name, such as \"v1\"\n",
    "* `MODEL_NAME` - with the model name you used above, such as \"scikit_learn_prediction\"\n",
    "* `PROJECT_ID` - with your project's id\n",
    "* `BUCKET_ID` - with the bucked id you created in the setup step\n",
    "\n",
    "Note: If you require a feature of XGBoost that isn’t available in the publicly released version yet, you can specify “runtimeVersion”: “HEAD” instead, and that would get the latest version of XGBoost available from the github repo. Otherwise the following versions will be used:\n",
    "* XGBoost: 0.6a2\n",
    "* Scikit-learn: 0.19.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! curl -X POST -H \"Content-Type: application/json\" \\\n",
    "   -d '{\"name\": \"[VERSION]\", \"deploymentUri\": \"gs://[BUCKET_ID]/\", \"runtimeVersion\": \"1.4\", \"framework\": \"SCIKIT_LEARN\"}' \\\n",
    "   -H \"Authorization: Bearer `gcloud auth print-access-token`\" \\\n",
    "    https://ml.googleapis.com/v1/projects/[PROJECT_ID]/models/[MODEL_NAME]/versions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5: Get online predictions\n",
    "To get online predictions, the data needs to be converted from a numpy array to a json array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data = []\n",
    "for i in range(len(test_features)):\n",
    "  data.append([])\n",
    "  for col in COLUMNS[:-1]: # Ignore the 'income-level' column as it is not in the feature set.\n",
    "    # Convert from numpy integers to standard integers\n",
    "    data[i].append(int(np.uint64(test_features[col][i]).item()))\n",
    "\n",
    "# Write the test data to a json file\n",
    "with open('data.json', 'w') as outfile:\n",
    "  json.dump(data, outfile)\n",
    "\n",
    "# Get one person that makes <50K and one that makes >50K to test our model.\n",
    "print('Show a person that makes <50K:')\n",
    "print('\\tFeatures: {0} --> Label: {1}\\n'.format(data[0], test_labels[0]))\n",
    "\n",
    "with open('less_than_50K.json', 'w') as outfile:\n",
    "  json.dump(data[0], outfile)\n",
    "\n",
    "  \n",
    "print('Show a person that makes >50K:')\n",
    "print('\\tFeatures: {0} --> Label: {1}'.format(data[2], test_labels[2]))\n",
    "\n",
    "with open('more_than_50K.json', 'w') as outfile:\n",
    "  json.dump(data[2], outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Gcloud to make online predictions\n",
    "Use the two people (as seen in the table) gathered in the previous step for the gcloud predictions.\n",
    "\n",
    "| **Person** | age | workclass | fnlwgt | education | education-num | marital-status | occupation | relationship | race | sex | capital-gain | capital-loss | hours-per-week | native-country || (Label) income-level|\n",
    "|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:||:-:\n",
    "| **1** | 25| 4 | 226802 | 1 | 7 | 4 | 7 | 3 | 2 | 1 | 0 | 0 | 40 | 38 || False (<50K) |\n",
    "| **2** | 28| 2 | 336951 | 7 | 12 | 2 | 11 | 0 | 4 | 1 | 0 | 0 | 40 | 38 || True (>50K) |\n",
    "\n",
    "** Replace: **\n",
    "* `VERSION` - with your version name, such as \"v1\"\n",
    "* `MODEL_NAME` - with the model name you used above, such as \"scikit_learn_prediction\"\n",
    "\n",
    "Test the model with an online prediction using the data of a person who makes <50K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! gcloud ml-engine predict --model [MODEL_NAME] --version [VERSION] --json-instances less_than_50K.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the model with an online prediction using the data of a person who makes >50K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! gcloud ml-engine predict --model [MODEL_NAME] --version [VERSION] --json-instances more_than_50K.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Python to make online predictions\n",
    "Test the model with the entire test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import googleapiclient.discovery\n",
    "\n",
    "# TODO: Fill these variables in with your variables\n",
    "PROJECT_ID = 'project_id'\n",
    "VERSION = 'version'  # Use your version name, such as \"v1\"'\n",
    "MODEL_NAME = 'model_name'  # Use the model name you used above, such as \"scikit_learn_prediction\"'\n",
    "\n",
    "service = googleapiclient.discovery.build('ml', 'v1')\n",
    "name = 'projects/{}/models/{}'.format(PROJECT_ID, MODEL_NAME)\n",
    "name += '/versions/{}'.format(VERSION)\n",
    "\n",
    "response = service.projects().predict(\n",
    "    name=name,\n",
    "    body={'instances': data}\n",
    ").execute()\n",
    "\n",
    "if 'error' in response:\n",
    "  print response['error']\n",
    "else:\n",
    "  print response['predictions']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
